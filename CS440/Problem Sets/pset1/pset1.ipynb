{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1d234e3f-af8b-4757-83f3-241b04b7a511"
    }
   },
   "source": [
    "# Problem Set 1: TensorFlow [50 pts]\n",
    "#### _Due date: Oct 12, 11:59pm_\n",
    "_Submission instructions will be posted separately on Piazza_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b07b9992-b592-4871-9f9a-3b0ae5fa8b5f"
    }
   },
   "source": [
    "**Note**: The following has been verified to work with TensorFlow 2.0\n",
    "\n",
    "\\* Adapted from official TensorFlow&trade; tour guide.\n",
    "\n",
    "TensorFlow is a powerful library for doing large-scale numerical computation. One of the tasks at which it excels is implementing and training deep neural networks. In this assignment you will learn the basic building blocks of a TensorFlow model while constructing a deep convolutional MNIST classifier.\n",
    "\n",
    "What you are expected to implement in this tutorial:\n",
    "\n",
    "* Create a softmax regression function that is a model for recognizing MNIST digits, based on looking at every pixel in the image\n",
    "\n",
    "* Use Tensorflow to train the model to recognize digits by having it \"look\" at thousands of examples\n",
    "\n",
    "* Check the model's accuracy with MNIST test data\n",
    "\n",
    "* Build, train, and test a multilayer convolutional neural network to improve the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "5516f610-f00c-43c3-bf19-4cf7ab9c089f"
    }
   },
   "source": [
    "## Data\n",
    "\n",
    "After importing tensorflow, we can download the MNIST dataset with the built-in TensorFlow/Keras method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages (3.3.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages (from matplotlib) (1.18.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages (from matplotlib) (2020.6.20)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages (from matplotlib) (7.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "## Build the CNN\n",
    "\n",
    "In this part we will build a customized TF2 Keras model. As input, a CNN takes tensors of shape (image_height, image_width, color_channels), ignoring the batch size. For MNIST, you will configure our CNN to process inputs of shape (28, 28, 1), which is the format of MNIST images. You can do this by passing the argument input_shape to our first layer.\n",
    "\n",
    "The overall architecture should be:\n",
    "\n",
    "```\n",
    "Model: \"customized_cnn\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "conv2d_2 (Conv2D)            multiple                  320       \n",
    "_________________________________________________________________\n",
    "max_pooling2d_1 (MaxPooling2 multiple                  0         \n",
    "_________________________________________________________________\n",
    "conv2d_3 (Conv2D)            multiple                  18496     \n",
    "_________________________________________________________________\n",
    "flatten_1 (Flatten)          multiple                  0         \n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              multiple                  7930880   \n",
    "_________________________________________________________________\n",
    "dense_3 (Dense)              multiple                  10250     \n",
    "=================================================================\n",
    "Total params: 7,959,946\n",
    "Trainable params: 7,959,946\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "```\n",
    "### First Convolutional Layer [5 pts]\n",
    "\n",
    "We can now implement our first layer. The convolution will compute 32 features for each 3x3 patch. The first two dimensions are the patch size, the next is the number of input channels, and the last is the number of output channels.\n",
    "\n",
    "### Max Pooling Layer [5 pts]\n",
    "\n",
    "We stack max pooling layer after the first convolutional layer. These pooling layers will perform max pooling for each 2x2 patch.\n",
    "\n",
    "### Second Convolutional Layer [5 pts]\n",
    "\n",
    "In order to build a deep network, we stack several layers of this type. The second layer will have 64 features for each 3x3 patch.\n",
    "\n",
    "\n",
    "### Fully Connected Layers [10 pts]\n",
    "\n",
    "Now that the image size has been reduced to 11x11, we add a fully-connected layer with 128 neurons to allow processing on the entire image. We reshape the tensor from the second convolutional layer into a batch of vectors before the fully connected layer.\n",
    "\n",
    "The output layer should also be implemented via a fully connect layer.\n",
    "\n",
    "\n",
    "### Complete the Computation Graph [15 pts]\n",
    "\n",
    "Please complete the following function:\n",
    "\n",
    "```def call(self, inputs, training=None, mask=None):```\n",
    "\n",
    "To apply the layer, we first reshape the input to a 4d tensor, with the second and third dimensions corresponding to image width and height, and the final dimension corresponding to the number of color channels (which is 1).\n",
    "\n",
    "We then convolve the reshaped input with the first convolutional layer and then the max pooling followed by the second convolutional layer. These convolutional layers and the pooling layer will reduce the image size to 11x11.\n",
    "\n",
    "### Dropout Layer [5 pts]\n",
    "Please add dropouts during training before each fully connected layers, as this helps avoid overfitting during training.\n",
    "https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "5e05f980-3d14-4367-b3d1-664249145b13"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.python.keras import Sequential \n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "58317664-8da3-4283-b3e5-35721687e7ab"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "class_names = ['0', '1', '2', '3', '4',\n",
    "               '5', '6', '7', '8', '9']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()\n",
    "\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbpresent": {
     "id": "71760e29-2b08-4259-93f1-ebe68cd74a6d"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":\\ Complete.\n"
     ]
    }
   ],
   "source": [
    "class CustomizedCNN(tf.keras.models.Model):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(CustomizedCNN, self).__init__()\n",
    "        self.conv2d1 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1))\n",
    "        self.max_pooling_2d = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(1,1))\n",
    "        self.conv2d2 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu')\n",
    "        self.flatted = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(234)\n",
    "        self.dense2 = tf.keras.layers.Dense(44)\n",
    "#         model = tf.keras.models.Sequential()\n",
    "#         model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "#         model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(1,1)))\n",
    "#         model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "        #raise NotImplementedError('Implement Using Keras Layers.')\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        x = tf.expand_dims(inputs, axis=-1)\n",
    "        x = self.conv2d1(x)\n",
    "        x = self.max_pooling_2d(x)\n",
    "        x = self.conv2d2(x)\n",
    "        x = self.flatted(x)\n",
    "        x = self.dense1(x)\n",
    "        return self.dense2(x)\n",
    "        #raise NotImplementedError('Build the CNN here.')\n",
    "\n",
    "print(\":\\ Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "5d0bae73-5677-437f-af00-0a880b753345"
    }
   },
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "5c52eeb2-1092-4d45-9e16-02219c82cb5e"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"customized_cnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              multiple                  320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            multiple                  18496     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  7922538   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  10340     \n",
      "=================================================================\n",
      "Total params: 7,951,694\n",
      "Trainable params: 7,951,694\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = CustomizedCNN()\n",
    "model.build(input_shape=(None, 28, 28))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f407d2b5-3b1b-4a88-881f-2d15b7a5c682"
    }
   },
   "source": [
    "We can specify a loss function just as easily. Loss indicates how bad the model's prediction was on a single example; we try to minimize that while training across all the examples. Here, our loss function is the cross-entropy between the target and the softmax activation function applied to the model's prediction. As in the beginners tutorial, we use the stable formulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbpresent": {
     "id": "cdb90d24-6a23-4969-8138-f37e7050062d"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":\\ Complete\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "print(\":\\ Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1a6f61e8-2ae0-4730-ad8c-35c683033b04"
    }
   },
   "source": [
    "## Train and Evaluate the Model [5 pts]\n",
    "\n",
    "We will use a more sophisticated ADAM optimizer instead of a Gradient Descent Optimizer.\n",
    "\n",
    "Feel free to run this code. Be aware that it does 10 training epochs and may take a while (possibly up to half an hour), depending on your processor.\n",
    "\n",
    "The final test set accuracy after running this code should be approximately 98.7%  -- not state of the art, but respectable.\n",
    "\n",
    "We have learned how to quickly and easily build, train, and evaluate a fairly sophisticated deep learning model using TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbpresent": {
     "id": "6b64378c-07fa-4f71-ad27-85e1fcd95310"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: (num_samples, timesteps, channels)\n",
      "Sequences: (60000, 28, 28)\n",
      "Targets:   (60000,)\n",
      "Expected: (num_samples, timesteps, channels)\n",
      "Sequences: (60000, 28, 28)\n",
      "Targets:   (60000,)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-4-bd4617ac2f70>:19 call  *\n        x = self.conv2d1(x)\n    /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__  **\n        outputs = call_fn(inputs, *args, **kwargs)\n    /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py:247 call\n        outputs = self._convolution_op(inputs, self.kernel)\n    /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py:1017 convolution_v2\n        name=name)\n    /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py:1147 convolution_internal\n        name=name)\n    /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py:2602 _conv2d_expanded_batch\n        name=name)\n    /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py:313 squeeze_batch_dims\n        out_reshaped = op(inp_reshaped)\n    /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py:979 conv2d\n        data_format=data_format, dilations=dilations, name=name)\n    /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:578 _apply_op_helper\n        param_name=input_name)\n    /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:61 _SatisfiesTypeConstraint\n        \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\n\n    TypeError: Value passed to parameter 'input' has DataType uint8 not in list of allowed values: float16, bfloat16, float32, float64, int32\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f65d38335a75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-4-bd4617ac2f70>:19 call  *\n        x = self.conv2d1(x)\n    /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__  **\n        outputs = call_fn(inputs, *args, **kwargs)\n    /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py:247 call\n        outputs = self._convolution_op(inputs, self.kernel)\n    /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py:1017 convolution_v2\n        name=name)\n    /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py:1147 convolution_internal\n        name=name)\n    /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py:2602 _conv2d_expanded_batch\n        name=name)\n    /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py:313 squeeze_batch_dims\n        out_reshaped = op(inp_reshaped)\n    /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py:979 conv2d\n        data_format=data_format, dilations=dilations, name=name)\n    /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:578 _apply_op_helper\n        param_name=input_name)\n    /Users/ginomcfino/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:61 _SatisfiesTypeConstraint\n        \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\n\n    TypeError: Value passed to parameter 'input' has DataType uint8 not in list of allowed values: float16, bfloat16, float32, float64, int32\n"
     ]
    }
   ],
   "source": [
    "# # Preprocess the data (these are NumPy arrays)\n",
    "# train_images = train_images.reshape(60000, 784).astype(\"float32\") / 255\n",
    "# test_images = test_images.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "# train_labels = train_labels.astype(\"float32\")\n",
    "# test_labels = test_labels.astype(\"float32\")\n",
    "\n",
    "# # Reserve 10,000 samples for validation\n",
    "# x_val = train_images[-10000:]\n",
    "# y_val = train_labels[-10000:]\n",
    "# x_train = train_images[:-10000]\n",
    "# y_train = train_labels[:-10000]\n",
    "\n",
    "#raise NotImplementedError('Update correct arguments for the fit method below.')\n",
    "# history = model.fit(train_images, train_labels, epochs=5) # Use correct args here.\n",
    "\n",
    "#x = tf.expand_dims(inputs, axis=-1)\n",
    "\n",
    "# image = tf.image.decode_jpeg(train_images)\n",
    "# image = tf.cast(image, tf.float32)\n",
    "\n",
    "def show_shapes(): # can make yours to take inputs; this'll use local variable values\n",
    "    print(\"Expected: (num_samples, timesteps, channels)\")\n",
    "    print(\"Sequences: {}\".format(train_images.shape))\n",
    "    print(\"Targets:   {}\".format(train_labels.shape))   \n",
    "\n",
    "x_images = np.asarray(train_images)\n",
    "x_labels   = np.asarray(train_labels)\n",
    "show_shapes()\n",
    "\n",
    "y_images = np.expand_dims(x_images, -1)\n",
    "y_targets  = np.expand_dims(x_labels, -1)\n",
    "show_shapes()\n",
    "\n",
    "x_train = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "x_test = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
    "\n",
    "history = model.fit(x_train, y_targets, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "ff342098-784a-4e20-ac34-b74ca8ebe839"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.9, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "d830cf58-fade-43e0-81c5-52632245d5d4"
    }
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
